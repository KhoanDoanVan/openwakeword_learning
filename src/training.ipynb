{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:53.375353Z",
     "start_time": "2025-11-18T10:32:53.373175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install openwakeword\n",
    "# !pip install speechbrain\n",
    "# !pip install datasets\n",
    "# !pip install scipy matplotlib"
   ],
   "id": "bf1cd8b402d1d68e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:53.380992Z",
     "start_time": "2025-11-18T10:32:53.378536Z"
    }
   },
   "source": [
    "import os\n",
    "import collections\n",
    "import numpy as np\n",
    "from numpy.lib.format import open_memmap\n",
    "from pathlib import Path\n",
    "\n",
    "from onnxruntime.transformers.shape_infer_helper import file_path\n",
    "from tqdm import tqdm\n",
    "import openwakeword\n",
    "# import openwakeword.data\n",
    "import openwakeword.utils\n",
    "import openwakeword.metrics\n",
    "\n",
    "\n",
    "import scipy\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import IPython.display as ipd\n",
    "\n",
    "import datasets\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:57.216744Z",
     "start_time": "2025-11-18T10:32:53.385707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "ds = datasets.load_dataset(\n",
    "    \"speech_commands\",\n",
    "    \"v0.02\",\n",
    "    split=\"test\",\n",
    "    streaming=True\n",
    ")\n",
    "ds_iter = iter(ds)\n",
    "\n",
    "os.makedirs(\"./data/speech_commands_test\", exist_ok=True)\n",
    "limit = 4890\n",
    "\n",
    "for i in tqdm(range(limit)):\n",
    "    output_file = f\"./data/speech_commands_test/{i:05d}.wav\"\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        continue\n",
    "\n",
    "    example = next(ds_iter)\n",
    "    wav_data = (example[\"audio\"][\"array\"] * 32767).astype(np.int16) # Convert to 16-bit PCM Format\n",
    "    scipy.io.wavfile.write(output_file, 16000, wav_data)"
   ],
   "id": "8ddc23338d400c2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4890/4890 [00:00<00:00, 16187.49it/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ⇲ Compute Audio Embeddings",
   "id": "2544e0ed47840239"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create audio pre-processing object to get openwakeword audio embeddings",
   "id": "641be6b3a8f77e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:57.221559Z",
     "start_time": "2025-11-18T10:32:57.219265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_dir = \"./resources/models\"\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ],
   "id": "b82c3e22d8e2fb00",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List Model and URL corresponding",
   "id": "33faea9030fb7677"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:57.237355Z",
     "start_time": "2025-11-18T10:32:57.234592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"embedding_model.onnx\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.onnx\",\n",
    "    \"embedding_model.tflite\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/embedding_model.tflite\",\n",
    "    \"melspectrogram.onnx\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.onnx\",\n",
    "    \"melspectrogram.tflite\": \"https://github.com/dscripka/openWakeWord/releases/download/v0.5.1/melspectrogram.tflite\"\n",
    "}"
   ],
   "id": "8265efbdf02c2237",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:57.244061Z",
     "start_time": "2025-11-18T10:32:57.240944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for filename, url in models.items():\n",
    "    file_path = os.path.join(model_dir, filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urllib.request.urlretrieve(url, file_path)\n",
    "    else:\n",
    "        print(f\"Found {filename}.\")\n"
   ],
   "id": "c1bc4464d4e43c4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embedding_model.onnx.\n",
      "Found embedding_model.tflite.\n",
      "Found melspectrogram.onnx.\n",
      "Found melspectrogram.tflite.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:32:57.723589Z",
     "start_time": "2025-11-18T10:32:57.248550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "F = openwakeword.utils.AudioFeatures(\n",
    "    melspec_model_path=f\"{model_dir}/melspectrogram.onnx\",\n",
    "    embedding_model_path=f\"{model_dir}/embedding_model.onnx\",\n",
    "    inference_framework=\"onnx\",\n",
    ")"
   ],
   "id": "f928427c248cb842",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ⌀ Negative Clips",
   "id": "e604f763a281c95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get negative example paths, filtering out clips that are too long or too short",
   "id": "3f33a00d191bc758"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cpu",
   "id": "b3545c2e01d84d01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:48:10.546279Z",
     "start_time": "2025-11-18T10:48:10.541048Z"
    }
   },
   "cell_type": "code",
   "source": "import openwakeword.data",
   "id": "e0ea19e124e8bbc6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T11:05:03.369312Z",
     "start_time": "2025-11-18T11:04:50.084465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "negative_clips, negative_durations = openwakeword.data.filter_audio_paths(\n",
    "    [\n",
    "        \"./data/fma_sample\",\n",
    "        \"./data/fsd50k_sample\",\n",
    "        \"./data/speech_commands_test\",\n",
    "    ],\n",
    "    min_length_secs=1.0, # minimum clip length in seconds\n",
    "    max_length_secs=60*30, # maximum clip length in seconds\n",
    "    duration_method=\"header\" # use the file header to calculate duration\n",
    ")\n",
    "\n",
    "print(f\"{len(negative_clips)} negative clips after filtering, representing ~{sum(negative_durations)//3600} hours\")"
   ],
   "id": "3d9de126558e1377",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 5687.62it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 112.25it/s]\n",
      "1000it [00:00, 13914.96it/s]\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 261.22it/s]\n",
      "4890it [00:00, 19923.89it/s]\n",
      "100%|██████████| 4890/4890 [00:07<00:00, 669.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5987 negative clips after filtering, representing ~5.0 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Use HuggingFace datasets to load files from disk by batches, because:\n",
    "- Load lazy\n",
    "- Memmory-Mapping for doesn't load entire in RAM\n",
    "- map() -> feature extraction, augmentation\n",
    "- filter() -> remove audio too long/short"
   ],
   "id": "5280621cd4c3337e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:04:24.140678Z",
     "start_time": "2025-11-18T12:04:23.315624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_dataset = datasets.Dataset.from_dict({\n",
    "    \"audio\": negative_clips\n",
    "})"
   ],
   "id": "661e9732da8bd77c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:05:21.191952Z",
     "start_time": "2025-11-18T12:05:20.756542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_dataset = audio_dataset.cast_column(\n",
    "    \"audio\",\n",
    "    datasets.Audio(sampling_rate=16000)\n",
    ")"
   ],
   "id": "230e78e76dfa7105",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Get Audio Embeddings (features) for negative clips and save to .npy file\n",
    "- Process files by batch and save to Numpy memory mapped file so that\n",
    "- An array larger than the available system memory can be created"
   ],
   "id": "786d2cfb3d0ce433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:10:56.676604Z",
     "start_time": "2025-11-18T12:10:56.672495Z"
    }
   },
   "cell_type": "code",
   "source": "batch_size = 64 # number of files to load, compute features, and write to mmap at a time",
   "id": "91fdac46c693fb0b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:11:58.984151Z",
     "start_time": "2025-11-18T12:11:58.978487Z"
    }
   },
   "cell_type": "code",
   "source": "clip_size = 3 # The desired window size (in seconds) for the trained openWakeWord model",
   "id": "975821b35739ea99",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:14:20.135547Z",
     "start_time": "2025-11-18T12:14:20.132079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_total = int(sum(negative_durations)//clip_size) # Maximum number of rows in mmap file\n",
    "\n",
    "N_total"
   ],
   "id": "12231ac32d787e71",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6441"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:14:15.696762Z",
     "start_time": "2025-11-18T12:14:14.613802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_feature_cols = F.get_embedding_shape(clip_size)\n",
    "\n",
    "n_feature_cols"
   ],
   "id": "e9733b406c7f4dc4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 96)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:16:05.549305Z",
     "start_time": "2025-11-18T12:16:05.546625Z"
    }
   },
   "cell_type": "code",
   "source": "output_file = \"negative_features.npy\"",
   "id": "8a1d55f3a239f995",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:16:37.143281Z",
     "start_time": "2025-11-18T12:16:37.138285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_array_shape = (N_total, n_feature_cols[0], n_feature_cols[1])\n",
    "\n",
    "output_array_shape"
   ],
   "id": "d1acc1a4ea4630bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6441, 28, 96)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:18:58.423728Z",
     "start_time": "2025-11-18T12:18:56.925477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fp = open_memmap(\n",
    "    output_file,\n",
    "    mode=\"w+\",\n",
    "    dtype=np.float32,\n",
    "    shape=output_array_shape\n",
    ")\n",
    "\n",
    "fp"
   ],
   "id": "48f8fe2cc99d4c4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
       "       shape=(6441, 28, 96), dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:19:57.045178Z",
     "start_time": "2025-11-18T12:19:57.042198Z"
    }
   },
   "cell_type": "code",
   "source": "row_counter = 0",
   "id": "b9a5919de5fb5280",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:33:44.844066Z",
     "start_time": "2025-11-18T12:33:36.990709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in tqdm(np.arange(0, audio_dataset.num_rows, batch_size)):\n",
    "    # Load data in batches and shape into rectangular array\n",
    "    wav_data = [\n",
    "        (j[\"array\"] * 32767).astype(np.int16) for j in audio_dataset[i:i + batch_size][\"audio\"]\n",
    "    ]\n",
    "\n",
    "    wav_data = openwakeword.data.stack_clips(\n",
    "        wav_data,\n",
    "        clip_size=16000*clip_size\n",
    "    ).astype(np.int16)\n",
    "\n",
    "    # Compute features (increase ncpu argument for faster processing)\n",
    "    features = F.embed_clips(\n",
    "        x=wav_data,\n",
    "        batch_size=1024,\n",
    "        ncpu=8\n",
    "    )\n",
    "\n",
    "    # Save computed features to mmap array file (stopping once the desired size is reached)\n",
    "    if row_counter + features.shape[0] > N_total:\n",
    "        fp[\n",
    "            row_counter:min(row_counter+features.shape[0], N_total),\n",
    "            :,\n",
    "            :\n",
    "        ] = features[\n",
    "            0:N_total - row_counter,\n",
    "            :,\n",
    "            :\n",
    "        ]\n",
    "\n",
    "        fp.flush()\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        fp[\n",
    "            row_counter:row_counter+features.shape[0],\n",
    "            :,\n",
    "            :\n",
    "        ] = features\n",
    "\n",
    "        row_counter += features.shape[0]\n",
    "        fp.flush()"
   ],
   "id": "130c604c46e9156d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:07<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T12:51:51.093555Z",
     "start_time": "2025-11-18T12:51:48.864626Z"
    }
   },
   "cell_type": "code",
   "source": "openwakeword.data.trim_mmap(output_file)",
   "id": "4c4198607ec5955b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trimming empty rows: 7it [00:00,  8.58it/s]                       \n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d3fcfbe4ad4803ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
